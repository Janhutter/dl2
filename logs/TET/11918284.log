[25/05/18 14:39:50] [utils.py:   82]: PyTorch Version: torch=2.5.0+cu124, cuda=12.4, cudnn=90100
[25/05/18 14:39:50] [utils.py:   83]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  IMG_SIZE: 32
  NUM_CHANNEL: 3
  NUM_CLASSES: 10
  NUM_EX: 10000
  SEVERITY: [5, 4, 3, 2, 1]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: /scratch-shared/tea2/cifar10
DESC: 
EARLY_STOP_BEGIN: 70
EARLY_STOP_PATIENCE: 30
EATA:
  D_MARGIN: 0.05
  E_MARGIN: 2.763102111592855
  FISHER_ALPHA: 2000.0
  FISHER_SIZE: 2000
  USE_FISHER: False
EBM:
  BUFFER_SIZE: 10000
  REINIT_FREQ: 0.05
  SGLD_LR: 0.1
  SGLD_STD: 0.01
  STEPS: 10
  UNCOND: uncond
LOG_DEST: pretrain_TET_all_sgd-1-0.3-1024_250518-143950.txt
LOG_TIME: 250518-143950
MODEL:
  ADAPTATION: source
  ADA_PARAM: ['all']
  ARCH: WRN2810_TET
  EPISODIC: False
OPTIM:
  BATCH_SIZE: 1024
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LAMBDA_CLS: 1.0
  LAMBDA_ENERGY: 0.0
  LR: 0.3
  METHOD: sgd
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  TEST_BATCH_SIZE: 128
  WD: 0.0005
OPTIM_ENERGY:
  BATCH_SIZE: 128
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
PL:
  ALPHA: 0.1
  THRESHOLD: 0.9
RNG_SEED: 1
SAR:
  MARGIN_E0: 2.763102111592855
SAVE_DIR: ./save/cifar10/bn-wrn-28-10-tet
SHOT:
  CLF_COEFF: 0.1
  THRESHOLD: 0.9
TEST:
  
[25/05/18 14:39:53] [param.py:   14]: adapting all weights
[25/05/18 14:39:53] [setada.py:  138]: model for adaptation: WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=10, bias=True)
)
[25/05/18 14:39:53] [setada.py:  139]: params for adaptation: all
[25/05/18 14:39:53] [setada.py:  140]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
Building model...
Files already downloaded and verified
Files already downloaded and verified
Training:   0%|          | 0/200 [00:00<?, ?epoch/s]Training:   0%|          | 1/200 [03:37<12:02:34, 217.86s/epoch]Training:   1%|          | 2/200 [07:08<11:44:20, 213.44s/epoch]Training:   2%|â–         | 3/200 [10:38<11:35:34, 211.85s/epoch]Training:   2%|â–         | 4/200 [14:08<11:29:35, 211.10s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   9%|â–‰         | 7/79 [00:05<00:52,  1.36batch/s][A
Testing:  20%|â–ˆâ–ˆ        | 16/79 [00:10<00:40,  1.57batch/s][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:15<00:33,  1.63batch/s][A
Testing:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/79 [00:20<00:27,  1.66batch/s][A
Testing:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/79 [00:26<00:21,  1.68batch/s][A
Testing:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/79 [00:31<00:15,  1.69batch/s][A
Testing:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/79 [00:36<00:10,  1.70batch/s][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [00:41<00:05,  1.70batch/s][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:46<00:00,  1.68batch/s]
[25/05/18 14:58:18] [train_TET.py:  226]: Test set Accuracy: 15.92
Training:   2%|â–Ž         | 5/200 [18:25<12:20:07, 227.73s/epoch]Training:   3%|â–Ž         | 6/200 [21:55<11:56:44, 221.67s/epoch]Training:   4%|â–Ž         | 7/200 [25:25<11:40:33, 217.79s/epoch]Training:   4%|â–         | 8/200 [28:54<11:28:45, 215.24s/epoch]Training:   4%|â–         | 9/200 [32:24<11:19:44, 213.53s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:  11%|â–ˆâ–        | 9/79 [00:05<00:42,  1.64batch/s][A
Testing:  23%|â–ˆâ–ˆâ–Ž       | 18/79 [00:10<00:36,  1.68batch/s][A
Testing:  34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [00:16<00:30,  1.69batch/s][A
Testing:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [00:21<00:25,  1.70batch/s][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:26<00:19,  1.70batch/s][A
Testing:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [00:31<00:14,  1.71batch/s][A
Testing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [00:37<00:09,  1.71batch/s][A
Testing:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [00:42<00:04,  1.71batch/s][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:45<00:00,  1.72batch/s]
[25/05/18 15:16:33] [train_TET.py:  226]: Test set Accuracy: 19.14
Training:   5%|â–Œ         | 10/200 [36:40<11:57:47, 226.67s/epoch]Training:   6%|â–Œ         | 11/200 [40:10<11:37:37, 221.47s/epoch]Training:   6%|â–Œ         | 12/200 [43:39<11:22:38, 217.86s/epoch]Training:   6%|â–‹         | 13/200 [47:09<11:11:25, 215.43s/epoch]Training:   7%|â–‹         | 14/200 [50:39<11:02:40, 213.77s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:  11%|â–ˆâ–        | 9/79 [00:05<00:42,  1.65batch/s][A
Testing:  23%|â–ˆâ–ˆâ–Ž       | 18/79 [00:10<00:36,  1.68batch/s][A
Testing:  34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [00:15<00:30,  1.70batch/s][A
Testing:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [00:21<00:25,  1.70batch/s][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:26<00:19,  1.70batch/s][A
Testing:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [00:31<00:14,  1.71batch/s][A
Testing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [00:37<00:09,  1.71batch/s][A
Testing:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [00:42<00:04,  1.71batch/s][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:45<00:00,  1.72batch/s]
[25/05/18 15:34:48] [train_TET.py:  226]: Test set Accuracy: 22.29
Training:   8%|â–Š         | 15/200 [54:55<11:38:26, 226.52s/epoch]Training:   8%|â–Š         | 16/200 [58:25<11:19:08, 221.46s/epoch]Training:   8%|â–Š         | 17/200 [1:01:55<11:04:34, 217.89s/epoch]Training:   9%|â–‰         | 18/200 [1:05:24<10:53:29, 215.44s/epoch]Training:  10%|â–‰         | 19/200 [1:08:54<10:44:35, 213.68s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:  11%|â–ˆâ–        | 9/79 [00:05<00:42,  1.64batch/s][A
Testing:  23%|â–ˆâ–ˆâ–Ž       | 18/79 [00:10<00:36,  1.68batch/s][A
Testing:  34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [00:16<00:30,  1.69batch/s][A
Testing:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [00:21<00:25,  1.70batch/s][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:26<00:19,  1.70batch/s][A
Testing:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [00:31<00:14,  1.71batch/s][A
Testing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [00:37<00:09,  1.71batch/s][A
Testing:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [00:42<00:04,  1.71batch/s][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:45<00:00,  1.72batch/s]
[25/05/18 15:53:03] [train_TET.py:  226]: Test set Accuracy: 14.09
Training:  10%|â–ˆ         | 20/200 [1:13:10<11:19:02, 226.35s/epoch]Training:  10%|â–ˆ         | 21/200 [1:16:39<11:00:00, 221.23s/epoch]Training:  11%|â–ˆ         | 22/200 [1:20:09<10:45:52, 217.71s/epoch]Training:  12%|â–ˆâ–        | 23/200 [1:23:38<10:34:52, 215.21s/epoch]Training:  12%|â–ˆâ–        | 24/200 [1:27:07<10:26:13, 213.49s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:  11%|â–ˆâ–        | 9/79 [00:05<00:42,  1.64batch/s][A
Testing:  23%|â–ˆâ–ˆâ–Ž       | 18/79 [00:10<00:36,  1.68batch/s][A
Testing:  34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [00:16<00:30,  1.69batch/s][A
Testing:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [00:21<00:25,  1.70batch/s][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:26<00:19,  1.70batch/s][A
Testing:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [00:31<00:14,  1.71batch/s][A
Testing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [00:37<00:09,  1.71batch/s][A
Testing:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [00:42<00:04,  1.71batch/s][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:45<00:00,  1.72batch/s]
[25/05/18 16:11:16] [train_TET.py:  226]: Test set Accuracy: 25.26
Training:  12%|â–ˆâ–Ž        | 25/200 [1:31:23<10:59:38, 226.16s/epoch]Training:  13%|â–ˆâ–Ž        | 26/200 [1:34:53<10:41:19, 221.15s/epoch]Training:  14%|â–ˆâ–Ž        | 27/200 [1:38:22<10:27:29, 217.62s/epoch]Training:  14%|â–ˆâ–        | 28/200 [1:41:51<10:16:49, 215.17s/epoch]Training:  14%|â–ˆâ–        | 29/200 [1:45:21<10:08:18, 213.44s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:  11%|â–ˆâ–        | 9/79 [00:05<00:42,  1.64batch/s][A
Testing:  23%|â–ˆâ–ˆâ–Ž       | 18/79 [00:10<00:36,  1.68batch/s][A
Testing:  34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [00:16<00:30,  1.69batch/s][A
Testing:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [00:21<00:25,  1.70batch/s][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:26<00:19,  1.70batch/s][A
Testing:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [00:31<00:14,  1.71batch/s][A
Testing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [00:37<00:09,  1.71batch/s][A
Testing:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [00:42<00:04,  1.71batch/s][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:45<00:00,  1.72batch/s]
[25/05/18 16:29:30] [train_TET.py:  226]: Test set Accuracy: 25.5
Training:  15%|â–ˆâ–Œ        | 30/200 [1:49:37<10:40:45, 226.15s/epoch]Training:  16%|â–ˆâ–Œ        | 31/200 [1:53:06<10:22:46, 221.10s/epoch]Training:  16%|â–ˆâ–Œ        | 32/200 [1:56:35<10:09:11, 217.57s/epoch]Training:  16%|â–ˆâ–‹        | 33/200 [2:00:05<9:58:40, 215.09s/epoch] Training:  17%|â–ˆâ–‹        | 34/200 [2:03:34<9:50:16, 213.35s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:  11%|â–ˆâ–        | 9/79 [00:05<00:42,  1.64batch/s][A
Testing:  23%|â–ˆâ–ˆâ–Ž       | 18/79 [00:10<00:36,  1.68batch/s][A
Testing:  34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [00:16<00:30,  1.69batch/s][A
Testing:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [00:21<00:25,  1.70batch/s][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:26<00:19,  1.70batch/s][A
Testing:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [00:31<00:14,  1.71batch/s][A
Testing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [00:37<00:09,  1.71batch/s][A
Testing:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [00:42<00:04,  1.71batch/s][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:45<00:00,  1.72batch/s]
[25/05/18 16:47:43] [train_TET.py:  226]: Test set Accuracy: 20.98
Training:  18%|â–ˆâ–Š        | 35/200 [2:07:50<10:21:34, 226.03s/epoch]Training:  18%|â–ˆâ–Š        | 36/200 [2:11:19<10:04:09, 221.03s/epoch]Training:  18%|â–ˆâ–Š        | 37/200 [2:14:48<9:50:57, 217.53s/epoch] Training:  19%|â–ˆâ–‰        | 38/200 [2:18:18<9:40:43, 215.09s/epoch]Training:  20%|â–ˆâ–‰        | 39/200 [2:21:47<9:32:31, 213.36s/epoch]slurmstepd: error: *** JOB 11918284 ON gcn11 CANCELLED AT 2025-05-18T17:03:55 ***

JOB STATISTICS
==============
Job ID: 11918284
Cluster: snellius
User/Group: jhutter/jhutter
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-19:17:24 core-walltime
Job Wall-clock time: 02:24:18
Memory Utilized: 2.02 GB
Memory Efficiency: 1.69% of 120.00 GB (120.00 GB/node)
