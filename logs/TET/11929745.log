[25/05/20 00:08:39] [utils.py:   82]: PyTorch Version: torch=2.5.0+cu124, cuda=12.4, cudnn=90100
[25/05/20 00:08:39] [utils.py:   83]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  IMG_SIZE: 32
  NUM_CHANNEL: 3
  NUM_CLASSES: 10
  NUM_EX: 10000
  SEVERITY: [5, 4, 3, 2, 1]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: /scratch-shared/tea2/cifar10
DESC: 
EARLY_STOP_BEGIN: 70
EARLY_STOP_PATIENCE: 30
EATA:
  D_MARGIN: 0.05
  E_MARGIN: 2.763102111592855
  FISHER_ALPHA: 2000.0
  FISHER_SIZE: 2000
  USE_FISHER: False
EBM:
  BUFFER_SIZE: 10000
  REINIT_FREQ: 0.05
  SGLD_LR: 0.1
  SGLD_STD: 0.01
  STEPS: 20
  UNCOND: uncond
LOG_DEST: pretrain_TET_bn_sgd-1-0.3-1024_250520-000839.txt
LOG_TIME: 250520-000839
MODEL:
  ADAPTATION: source
  ADA_PARAM: ['bn']
  ARCH: WRN2810_TET
  EPISODIC: False
OPTIM:
  BATCH_SIZE: 1024
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LAMBDA_CLS: 1.0
  LAMBDA_ENERGY: -1.0
  LR: 0.3
  METHOD: sgd
  MOMENTUM: 0.9
  NESTEROV: True
  N_EPOCHS: 200
  SCHEDULER_GAMMA: 0.2
  SCHEDULER_MILESTONES: [60, 120, 160]
  STEPS: 1
  TEST_BATCH_SIZE: 128
  WD: 0.0005
OPTIM_ENERGY:
  BATCH_SIZE: 128
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
PL:
  ALPHA: 0.1
  THRESHOLD: 0.9
RNG_SEED: 1
SAR:
  MARGIN_E0: 2.763102111592855
SAVE_DIR: ./save/cifar10/bn-wrn-28-10-tet
SHOT:
  CLF_COEFF: 0.1
  THRESHOLD: 0.9
TEST:
  
[25/05/20 00:08:44] [param.py:   18]: adapting weights of batch-normalization layer
[25/05/20 00:08:45] [setada.py:  138]: model for adaptation: WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=10, bias=True)
)
[25/05/20 00:08:45] [setada.py:  139]: params for adaptation: ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn2.weight', 'block1.layer.0.bn2.bias', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn2.weight', 'block1.layer.1.bn2.bias', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn2.weight', 'block1.layer.2.bn2.bias', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn2.weight', 'block1.layer.3.bn2.bias', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn2.weight', 'block2.layer.0.bn2.bias', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn2.weight', 'block2.layer.1.bn2.bias', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn2.weight', 'block2.layer.2.bn2.bias', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn2.weight', 'block2.layer.3.bn2.bias', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn2.weight', 'block3.layer.0.bn2.bias', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn2.weight', 'block3.layer.1.bn2.bias', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn2.weight', 'block3.layer.2.bn2.bias', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn2.weight', 'block3.layer.3.bn2.bias', 'bn1.weight', 'bn1.bias']
[25/05/20 00:08:45] [setada.py:  140]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
Building model...
Files already downloaded and verified
Files already downloaded and verified
Training:   0%|          | 0/200 [00:00<?, ?epoch/s]Training:   0%|          | 1/200 [06:35<21:50:35, 395.15s/epoch]Training:   1%|          | 2/200 [13:06<21:36:44, 392.95s/epoch]Training:   2%|â–         | 3/200 [19:37<21:26:41, 391.88s/epoch]Training:   2%|â–         | 4/200 [26:07<21:18:28, 391.37s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   5%|â–Œ         | 4/79 [00:05<01:36,  1.29s/batch][A
Testing:  11%|â–ˆâ–        | 9/79 [00:10<01:19,  1.13s/batch][A
Testing:  18%|â–ˆâ–Š        | 14/79 [00:15<01:10,  1.09s/batch][A
Testing:  24%|â–ˆâ–ˆâ–       | 19/79 [00:20<01:04,  1.07s/batch][A
Testing:  30%|â–ˆâ–ˆâ–ˆ       | 24/79 [00:25<00:58,  1.06s/batch][A
Testing:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 29/79 [00:31<00:52,  1.05s/batch][A
Testing:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/79 [00:36<00:47,  1.05s/batch][A
Testing:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/79 [00:41<00:41,  1.05s/batch][A
Testing:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/79 [00:46<00:36,  1.05s/batch][A
Testing:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/79 [00:52<00:31,  1.04s/batch][A
Testing:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [00:57<00:26,  1.04s/batch][A
Testing:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/79 [01:02<00:20,  1.04s/batch][A
Testing:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/79 [01:07<00:15,  1.04s/batch][A
Testing:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/79 [01:12<00:10,  1.04s/batch][A
Testing:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/79 [01:18<00:05,  1.04s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:22<00:00,  1.05s/batch]
[25/05/20 00:42:46] [train_TET.py:  224]: Test set Accuracy: 22.52
/gpfs/home5/jhutter/dl2/train_TET.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(os.path.join('ckpt', cfg.CORRUPTION.DATASET, cfg.MODEL.ARCH, f"TET_epoch_{epoch}.pth"))
Training:   2%|â–Ž         | 5/200 [34:01<22:48:35, 421.11s/epoch]Training:   3%|â–Ž         | 6/200 [40:32<22:08:08, 410.77s/epoch]Training:   4%|â–Ž         | 7/200 [47:02<21:39:53, 404.11s/epoch]Training:   4%|â–         | 8/200 [53:33<21:19:09, 399.74s/epoch]Training:   4%|â–         | 9/200 [1:00:03<21:03:09, 396.80s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:20,  1.09s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:10<01:13,  1.06s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:15<01:07,  1.05s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:21<01:01,  1.05s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:26<00:56,  1.05s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:31<00:51,  1.04s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:36<00:45,  1.04s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:41<00:40,  1.04s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:47<00:35,  1.04s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:52<00:30,  1.04s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [00:57<00:25,  1.04s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:02<00:19,  1.04s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:07<00:14,  1.04s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:13<00:09,  1.04s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:18<00:04,  1.04s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:21<00:00,  1.03s/batch]
[25/05/20 01:16:40] [train_TET.py:  224]: Test set Accuracy: 10.0
Training:   5%|â–Œ         | 10/200 [1:07:55<22:10:01, 420.01s/epoch]Training:   6%|â–Œ         | 11/200 [1:14:24<21:33:40, 410.69s/epoch]Training:   6%|â–Œ         | 12/200 [1:20:54<21:06:30, 404.21s/epoch]Training:   6%|â–‹         | 13/200 [1:27:23<20:45:32, 399.64s/epoch]Training:   7%|â–‹         | 14/200 [1:33:52<20:29:04, 396.48s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:20,  1.09s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:10<01:13,  1.06s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:15<01:07,  1.05s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:21<01:01,  1.05s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:26<00:56,  1.05s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:31<00:51,  1.04s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:36<00:45,  1.04s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:41<00:40,  1.04s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:47<00:35,  1.04s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:52<00:30,  1.04s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [00:57<00:25,  1.04s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:02<00:19,  1.04s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:07<00:14,  1.04s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:13<00:09,  1.04s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:18<00:04,  1.04s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:21<00:00,  1.03s/batch]
[25/05/20 01:50:28] [train_TET.py:  224]: Test set Accuracy: 10.0
Training:   8%|â–Š         | 15/200 [1:41:43<21:31:45, 418.95s/epoch]Training:   8%|â–Š         | 16/200 [1:48:12<20:57:01, 409.90s/epoch]Training:   8%|â–Š         | 17/200 [1:54:41<20:31:04, 403.63s/epoch]Training:   9%|â–‰         | 18/200 [2:01:10<20:11:00, 399.23s/epoch]Training:  10%|â–‰         | 19/200 [2:07:40<19:55:27, 396.28s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:20,  1.09s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:10<01:13,  1.06s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:15<01:07,  1.05s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:21<01:01,  1.05s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:26<00:56,  1.04s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:31<00:51,  1.04s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:36<00:45,  1.04s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:41<00:40,  1.04s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:47<00:35,  1.04s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:52<00:30,  1.04s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [00:57<00:24,  1.04s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:02<00:19,  1.04s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:07<00:14,  1.04s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:13<00:09,  1.04s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:18<00:04,  1.04s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:21<00:00,  1.03s/batch]
[25/05/20 02:24:15] [train_TET.py:  224]: Test set Accuracy: 10.0
Training:  10%|â–ˆ         | 20/200 [2:15:31<20:56:12, 418.73s/epoch]Training:  10%|â–ˆ         | 21/200 [2:22:00<20:22:36, 409.81s/epoch]Training:  11%|â–ˆ         | 22/200 [2:28:28<19:57:09, 403.54s/epoch]Training:  12%|â–ˆâ–        | 23/200 [2:34:57<19:37:29, 399.15s/epoch]Training:  12%|â–ˆâ–        | 24/200 [2:41:26<19:21:52, 396.09s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:20,  1.09s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:10<01:13,  1.06s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:15<01:07,  1.05s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:21<01:01,  1.05s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:26<00:56,  1.04s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:31<00:51,  1.04s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:36<00:45,  1.04s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:41<00:40,  1.04s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:47<00:35,  1.04s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:52<00:30,  1.04s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [00:57<00:24,  1.04s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:02<00:19,  1.04s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:07<00:14,  1.04s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:13<00:09,  1.04s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:18<00:04,  1.04s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:21<00:00,  1.03s/batch]
[25/05/20 02:58:02] [train_TET.py:  224]: Test set Accuracy: 10.0
Training:  12%|â–ˆâ–Ž        | 25/200 [2:49:17<20:20:55, 418.61s/epoch]Training:  13%|â–ˆâ–Ž        | 26/200 [2:55:46<19:48:02, 409.67s/epoch]slurmstepd: error: *** JOB 11929745 ON gcn31 CANCELLED AT 2025-05-20T03:08:48 DUE TO TIME LIMIT ***

JOB STATISTICS
==============
Job ID: 11929745
Cluster: snellius
User/Group: jhutter/jhutter
State: TIMEOUT (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 2-06:08:24 core-walltime
Job Wall-clock time: 03:00:28
Memory Utilized: 2.16 GB
Memory Efficiency: 1.80% of 120.00 GB (120.00 GB/node)
