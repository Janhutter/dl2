[25/05/16 02:48:02] [utils.py:   80]: PyTorch Version: torch=2.5.0+cu124, cuda=12.4, cudnn=90100
[25/05/16 02:48:02] [utils.py:   81]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  IMG_SIZE: 32
  NUM_CHANNEL: 3
  NUM_CLASSES: 10
  NUM_EX: 10000
  SEVERITY: [5, 4, 3, 2, 1]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: /scratch-shared/tea/cifar10
DESC: 
EARLY_STOP_PATIENCE: 20
EATA:
  D_MARGIN: 0.05
  E_MARGIN: 2.763102111592855
  FISHER_ALPHA: 2000.0
  FISHER_SIZE: 2000
  USE_FISHER: False
EBM:
  BUFFER_SIZE: 10000
  REINIT_FREQ: 0.05
  SGLD_LR: 0.1
  SGLD_STD: 0.01
  STEPS: 10
  UNCOND: uncond
LOG_DEST: pretrain_TET_bn_sgd-1-0.1-1024_250516-024802.txt
LOG_TIME: 250516-024802
MODEL:
  ADAPTATION: source
  ADA_PARAM: ['bn']
  ARCH: WRN2810_TET
  EPISODIC: False
OPTIM:
  BATCH_SIZE: 1024
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LR: 0.1
  METHOD: sgd
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  TEST_BATCH_SIZE: 128
  WD: 0.0005
OPTIM_ENERGY:
  BATCH_SIZE: 128
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
PL:
  ALPHA: 0.1
  THRESHOLD: 0.9
RNG_SEED: 1
SAR:
  MARGIN_E0: 2.763102111592855
SAVE_DIR: ./save/cifar10/bn-wrn-28-10-tet
SHOT:
  CLF_COEFF: 0.1
  THRESHOLD: 0.9
TEST:
  
[25/05/16 02:48:03] [utils.py:   80]: PyTorch Version: torch=2.5.0+cu124, cuda=12.4, cudnn=90100
[25/05/16 02:48:03] [utils.py:   81]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  IMG_SIZE: 32
  NUM_CHANNEL: 3
  NUM_CLASSES: 10
  NUM_EX: 10000
  SEVERITY: [5, 4, 3, 2, 1]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: /scratch-shared/tea/cifar10
DESC: 
EARLY_STOP_PATIENCE: 20
EATA:
  D_MARGIN: 0.05
  E_MARGIN: 2.763102111592855
  FISHER_ALPHA: 2000.0
  FISHER_SIZE: 2000
  USE_FISHER: False
EBM:
  BUFFER_SIZE: 10000
  REINIT_FREQ: 0.05
  SGLD_LR: 0.1
  SGLD_STD: 0.01
  STEPS: 10
  UNCOND: uncond
LOG_DEST: pretrain_TET_bn_sgd-1-0.1-1024_250516-024802.txt
LOG_TIME: 250516-024802
MODEL:
  ADAPTATION: source
  ADA_PARAM: ['bn']
  ARCH: WRN2810_TET
  EPISODIC: False
OPTIM:
  BATCH_SIZE: 1024
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LR: 0.1
  METHOD: sgd
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  TEST_BATCH_SIZE: 128
  WD: 0.0005
OPTIM_ENERGY:
  BATCH_SIZE: 128
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
PL:
  ALPHA: 0.1
  THRESHOLD: 0.9
RNG_SEED: 1
SAR:
  MARGIN_E0: 2.763102111592855
SAVE_DIR: ./save/cifar10/bn-wrn-28-10-tet
SHOT:
  CLF_COEFF: 0.1
  THRESHOLD: 0.9
TEST:
  
[25/05/16 02:48:03] [param.py:   18]: adapting weights of batch-normalization layer
[25/05/16 02:48:03] [setada.py:  138]: model for adaptation: WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=10, bias=True)
)
[25/05/16 02:48:03] [setada.py:  139]: params for adaptation: ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn2.weight', 'block1.layer.0.bn2.bias', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn2.weight', 'block1.layer.1.bn2.bias', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn2.weight', 'block1.layer.2.bn2.bias', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn2.weight', 'block1.layer.3.bn2.bias', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn2.weight', 'block2.layer.0.bn2.bias', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn2.weight', 'block2.layer.1.bn2.bias', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn2.weight', 'block2.layer.2.bn2.bias', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn2.weight', 'block2.layer.3.bn2.bias', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn2.weight', 'block3.layer.0.bn2.bias', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn2.weight', 'block3.layer.1.bn2.bias', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn2.weight', 'block3.layer.2.bn2.bias', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn2.weight', 'block3.layer.3.bn2.bias', 'bn1.weight', 'bn1.bias']
[25/05/16 02:48:03] [setada.py:  140]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
Building model...
Files already downloaded and verified
Files already downloaded and verified
Training:   0%|          | 0/200 [00:00<?, ?epoch/s]Training:   0%|          | 1/200 [04:23<14:35:20, 263.92s/epoch]Training:   1%|          | 2/200 [08:43<14:23:26, 261.65s/epoch]Training:   2%|â–         | 3/200 [13:03<14:16:01, 260.72s/epoch]Training:   2%|â–         | 4/200 [17:22<14:09:47, 260.14s/epoch]Training:   2%|â–Ž         | 5/200 [21:42<14:04:20, 259.80s/epoch]Training:   3%|â–Ž         | 6/200 [26:01<13:59:26, 259.62s/epoch]Training:   4%|â–Ž         | 7/200 [30:20<13:54:40, 259.48s/epoch]Training:   4%|â–         | 8/200 [34:40<13:50:50, 259.64s/epoch]Training:   4%|â–         | 9/200 [38:59<13:45:59, 259.47s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   5%|â–Œ         | 4/79 [00:05<01:40,  1.34s/batch][A
Testing:  11%|â–ˆâ–        | 9/79 [00:10<01:22,  1.19s/batch][A
Testing:  18%|â–ˆâ–Š        | 14/79 [00:16<01:14,  1.14s/batch][A
Testing:  24%|â–ˆâ–ˆâ–       | 19/79 [00:21<01:07,  1.13s/batch][A
Testing:  30%|â–ˆâ–ˆâ–ˆ       | 24/79 [00:27<01:01,  1.12s/batch][A
Testing:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 29/79 [00:32<00:55,  1.11s/batch][A
Testing:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/79 [00:38<00:49,  1.11s/batch][A
Testing:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/79 [00:43<00:44,  1.11s/batch][A
Testing:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/79 [00:49<00:38,  1.10s/batch][A
Testing:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/79 [00:54<00:33,  1.10s/batch][A
Testing:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [01:00<00:27,  1.10s/batch][A
Testing:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/79 [01:05<00:22,  1.10s/batch][A
Testing:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/79 [01:11<00:16,  1.10s/batch][A
Testing:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/79 [01:16<00:11,  1.10s/batch][A
Testing:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/79 [01:22<00:05,  1.10s/batch][A
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:27<00:00,  1.08s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:27<00:00,  1.11s/batch]
[25/05/16 03:32:52] [train_TET.py:  177]: Test set Accuracy: 19.48
Training:   5%|â–Œ         | 10/200 [44:46<15:07:15, 286.50s/epoch]Training:   6%|â–Œ         | 11/200 [49:06<14:36:24, 278.23s/epoch]Training:   6%|â–Œ         | 12/200 [53:25<14:13:46, 272.48s/epoch]Training:   6%|â–‹         | 13/200 [57:44<13:56:50, 268.50s/epoch]Training:   7%|â–‹         | 14/200 [1:02:04<13:43:41, 265.71s/epoch]Training:   8%|â–Š         | 15/200 [1:06:23<13:33:17, 263.77s/epoch]Training:   8%|â–Š         | 16/200 [1:10:42<13:24:41, 262.40s/epoch]Training:   8%|â–Š         | 17/200 [1:15:01<13:17:25, 261.45s/epoch]Training:   9%|â–‰         | 18/200 [1:19:20<13:11:00, 260.77s/epoch]Training:  10%|â–‰         | 19/200 [1:23:40<13:05:15, 260.30s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:24,  1.15s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:11<01:17,  1.12s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:16<01:11,  1.11s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:22<01:05,  1.11s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:27<00:59,  1.10s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:33<00:54,  1.10s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:38<00:48,  1.10s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:44<00:42,  1.10s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:49<00:37,  1.10s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:55<00:31,  1.10s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:00<00:26,  1.10s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:06<00:20,  1.10s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:11<00:15,  1.10s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:17<00:09,  1.10s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:22<00:04,  1.10s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:26<00:00,  1.10s/batch]
[25/05/16 04:17:32] [train_TET.py:  177]: Test set Accuracy: 21.6
Training:  10%|â–ˆ         | 20/200 [1:29:26<14:18:11, 286.06s/epoch]Training:  10%|â–ˆ         | 21/200 [1:33:45<13:49:31, 278.05s/epoch]Training:  11%|â–ˆ         | 22/200 [1:38:05<13:28:15, 272.45s/epoch]Training:  12%|â–ˆâ–        | 23/200 [1:42:24<13:12:09, 268.53s/epoch]Training:  12%|â–ˆâ–        | 24/200 [1:46:43<12:59:40, 265.80s/epoch]Training:  12%|â–ˆâ–Ž        | 25/200 [1:51:03<12:49:28, 263.82s/epoch]Training:  13%|â–ˆâ–Ž        | 26/200 [1:55:22<12:41:11, 262.48s/epoch]Training:  14%|â–ˆâ–Ž        | 27/200 [1:59:41<12:34:05, 261.54s/epoch]Training:  14%|â–ˆâ–        | 28/200 [2:04:00<12:27:42, 260.83s/epoch]Training:  14%|â–ˆâ–        | 29/200 [2:08:20<12:22:05, 260.38s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:24,  1.15s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:11<01:17,  1.12s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:16<01:11,  1.11s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:22<01:05,  1.11s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:27<00:59,  1.10s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:33<00:54,  1.10s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:38<00:48,  1.10s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:44<00:42,  1.10s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:49<00:37,  1.10s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:55<00:31,  1.10s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:00<00:26,  1.10s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:06<00:20,  1.10s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:11<00:15,  1.10s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:17<00:09,  1.10s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:22<00:04,  1.10s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:26<00:00,  1.10s/batch]
[25/05/16 05:02:12] [train_TET.py:  177]: Test set Accuracy: 22.82
Training:  15%|â–ˆâ–Œ        | 30/200 [2:14:06<13:30:37, 286.10s/epoch]Training:  16%|â–ˆâ–Œ        | 31/200 [2:18:25<13:03:07, 278.04s/epoch]Training:  16%|â–ˆâ–Œ        | 32/200 [2:22:44<12:42:48, 272.43s/epoch]Training:  16%|â–ˆâ–‹        | 33/200 [2:27:04<12:27:13, 268.47s/epoch]Training:  17%|â–ˆâ–‹        | 34/200 [2:31:23<12:15:02, 265.68s/epoch]Training:  18%|â–ˆâ–Š        | 35/200 [2:35:42<12:05:11, 263.71s/epoch]Training:  18%|â–ˆâ–Š        | 36/200 [2:40:01<11:57:04, 262.35s/epoch]Training:  18%|â–ˆâ–Š        | 37/200 [2:44:20<11:50:13, 261.43s/epoch]Training:  19%|â–ˆâ–‰        | 38/200 [2:48:40<11:44:03, 260.76s/epoch]Training:  20%|â–ˆâ–‰        | 39/200 [2:52:59<11:38:25, 260.28s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:24,  1.14s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:11<01:17,  1.12s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:16<01:10,  1.11s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:22<01:05,  1.11s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:27<00:59,  1.10s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:33<00:53,  1.10s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:38<00:48,  1.10s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:44<00:42,  1.10s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:49<00:37,  1.10s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:55<00:31,  1.10s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:00<00:26,  1.10s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:06<00:20,  1.10s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:11<00:15,  1.10s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:17<00:09,  1.10s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:22<00:04,  1.10s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:26<00:00,  1.09s/batch]
[25/05/16 05:46:51] [train_TET.py:  177]: Test set Accuracy: 25.2
Training:  20%|â–ˆâ–ˆ        | 40/200 [2:58:45<12:42:31, 285.95s/epoch]Training:  20%|â–ˆâ–ˆ        | 41/200 [3:03:04<12:16:32, 277.94s/epoch]Training:  21%|â–ˆâ–ˆ        | 42/200 [3:07:23<11:57:11, 272.35s/epoch]Training:  22%|â–ˆâ–ˆâ–       | 43/200 [3:11:42<11:42:25, 268.44s/epoch]Training:  22%|â–ˆâ–ˆâ–       | 44/200 [3:16:02<11:30:44, 265.67s/epoch]Training:  22%|â–ˆâ–ˆâ–Ž       | 45/200 [3:20:21<11:21:23, 263.76s/epoch]Training:  23%|â–ˆâ–ˆâ–Ž       | 46/200 [3:24:40<11:13:36, 262.44s/epoch]Training:  24%|â–ˆâ–ˆâ–Ž       | 47/200 [3:29:00<11:06:42, 261.45s/epoch]Training:  24%|â–ˆâ–ˆâ–       | 48/200 [3:33:19<11:00:36, 260.77s/epoch]Training:  24%|â–ˆâ–ˆâ–       | 49/200 [3:37:38<10:55:04, 260.30s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:24,  1.15s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:11<01:17,  1.12s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:16<01:11,  1.11s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:22<01:05,  1.11s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:27<00:59,  1.10s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:33<00:53,  1.10s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:38<00:48,  1.10s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:44<00:42,  1.10s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:49<00:37,  1.10s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:55<00:31,  1.10s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:00<00:26,  1.10s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:06<00:20,  1.10s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:11<00:15,  1.10s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:17<00:09,  1.10s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:22<00:04,  1.10s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:26<00:00,  1.10s/batch]
[25/05/16 06:31:30] [train_TET.py:  177]: Test set Accuracy: 24.89
Training:  25%|â–ˆâ–ˆâ–Œ       | 50/200 [3:43:24<11:54:54, 285.96s/epoch]Model did not improve (eval acc: 24.89, best: 25.2,10/20 in a row)
Training:  26%|â–ˆâ–ˆâ–Œ       | 51/200 [3:47:43<11:30:14, 277.95s/epoch]Training:  26%|â–ˆâ–ˆâ–Œ       | 52/200 [3:52:02<11:11:45, 272.34s/epoch]Training:  26%|â–ˆâ–ˆâ–‹       | 53/200 [3:56:21<10:57:33, 268.39s/epoch]Training:  27%|â–ˆâ–ˆâ–‹       | 54/200 [4:00:41<10:46:23, 265.64s/epoch]Training:  28%|â–ˆâ–ˆâ–Š       | 55/200 [4:05:00<10:37:17, 263.71s/epoch]Training:  28%|â–ˆâ–ˆâ–Š       | 56/200 [4:09:19<10:29:40, 262.37s/epoch]Training:  28%|â–ˆâ–ˆâ–Š       | 57/200 [4:13:38<10:23:08, 261.46s/epoch]Training:  29%|â–ˆâ–ˆâ–‰       | 58/200 [4:17:58<10:17:32, 260.93s/epoch]Training:  30%|â–ˆâ–ˆâ–‰       | 59/200 [4:22:17<10:12:04, 260.46s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:25,  1.15s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:11<01:17,  1.12s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:16<01:10,  1.11s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:22<01:05,  1.10s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:27<00:59,  1.10s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:33<00:53,  1.10s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:38<00:48,  1.10s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:44<00:42,  1.10s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:49<00:37,  1.10s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:55<00:31,  1.10s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:00<00:26,  1.10s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:06<00:20,  1.10s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:11<00:15,  1.10s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:17<00:09,  1.10s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:22<00:04,  1.10s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:26<00:00,  1.09s/batch]
[25/05/16 07:16:10] [train_TET.py:  177]: Test set Accuracy: 28.48
Training:  30%|â–ˆâ–ˆâ–ˆ       | 60/200 [4:28:03<11:07:34, 286.10s/epoch]Training:  30%|â–ˆâ–ˆâ–ˆ       | 61/200 [4:32:23<10:44:06, 278.03s/epoch]Training:  31%|â–ˆâ–ˆâ–ˆ       | 62/200 [4:36:42<10:26:36, 272.44s/epoch]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [4:41:01<10:13:02, 268.48s/epoch]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [4:45:20<10:02:14, 265.69s/epoch]Training:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [4:49:40<9:53:24, 263.74s/epoch] Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [4:53:59<9:45:59, 262.39s/epoch]Training:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [4:58:18<9:39:33, 261.45s/epoch]Training:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [5:02:37<9:33:41, 260.77s/epoch]Training:  34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [5:06:56<9:28:16, 260.28s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:24,  1.14s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:11<01:17,  1.12s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:16<01:11,  1.11s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:22<01:05,  1.11s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:27<00:59,  1.10s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:33<00:54,  1.10s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:38<00:48,  1.10s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:44<00:42,  1.10s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:49<00:37,  1.10s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:55<00:31,  1.10s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:00<00:26,  1.10s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:06<00:20,  1.10s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:11<00:15,  1.10s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:17<00:09,  1.10s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:22<00:04,  1.10s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:26<00:00,  1.10s/batch]
[25/05/16 08:00:49] [train_TET.py:  177]: Test set Accuracy: 28.44
Training:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [5:12:42<10:19:37, 285.98s/epoch]Model did not improve (eval acc: 28.44, best: 28.48,10/20 in a row)
Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [5:17:02<9:57:39, 277.98s/epoch] Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [5:21:21<9:41:07, 272.40s/epoch]Training:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [5:26:10<9:47:22, 277.50s/epoch]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [5:31:00<9:50:13, 281.06s/epoch]Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [5:35:19<9:32:01, 274.57s/epoch]Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [5:40:19<9:42:53, 282.04s/epoch]Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [5:44:58<9:36:32, 281.24s/epoch]Training:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [5:49:17<9:18:24, 274.63s/epoch]Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [5:53:37<9:04:31, 270.01s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:24,  1.15s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:11<01:17,  1.12s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:16<01:10,  1.11s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:22<01:05,  1.10s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:27<00:59,  1.10s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:33<00:53,  1.10s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:38<00:48,  1.10s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:44<00:42,  1.10s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:49<00:37,  1.10s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:55<00:31,  1.10s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:00<00:26,  1.10s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:06<00:20,  1.10s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:11<00:15,  1.10s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:17<00:09,  1.10s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:22<00:04,  1.10s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:26<00:00,  1.09s/batch]
[25/05/16 08:47:29] [train_TET.py:  177]: Test set Accuracy: 29.06
Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [5:59:22<9:45:31, 292.76s/epoch]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [6:03:42<9:20:47, 282.75s/epoch]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [6:08:01<9:02:18, 275.75s/epoch]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [6:12:20<8:48:05, 270.81s/epoch]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [6:16:40<8:36:53, 267.36s/epoch]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [6:20:59<8:27:47, 264.93s/epoch]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [6:25:18<8:20:08, 263.23s/epoch]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [6:29:38<8:13:29, 262.03s/epoch]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [6:34:17<8:18:43, 267.17s/epoch]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [6:39:36<8:42:55, 282.66s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:24,  1.15s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:11<01:17,  1.12s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:16<01:11,  1.11s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:22<01:05,  1.11s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:27<00:59,  1.10s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:33<00:54,  1.10s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:38<00:48,  1.10s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:44<00:42,  1.10s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:49<00:37,  1.10s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:55<00:31,  1.10s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:00<00:26,  1.10s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:06<00:20,  1.10s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:11<00:15,  1.10s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:17<00:09,  1.10s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:22<00:04,  1.10s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:26<00:00,  1.10s/batch]
[25/05/16 09:33:28] [train_TET.py:  177]: Test set Accuracy: 28.54
Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [6:45:22<9:13:08, 301.71s/epoch]Model did not improve (eval acc: 28.54, best: 29.06,10/20 in a row)
Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [6:49:42<8:45:33, 289.30s/epoch]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [6:54:01<8:24:29, 280.28s/epoch]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [6:58:21<8:08:38, 274.00s/epoch]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [7:02:44<7:58:27, 270.82s/epoch]Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [7:07:03<7:47:50, 267.34s/epoch]Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [7:11:22<7:39:09, 264.90s/epoch]Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [7:15:42<7:31:49, 263.19s/epoch]Training:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [7:20:01<7:25:23, 262.00s/epoch]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [7:24:20<7:19:48, 261.27s/epoch]
Testing:   0%|          | 0/79 [00:00<?, ?batch/s][A
Testing:   6%|â–‹         | 5/79 [00:05<01:25,  1.15s/batch][A
Testing:  13%|â–ˆâ–Ž        | 10/79 [00:11<01:17,  1.12s/batch][A
Testing:  19%|â–ˆâ–‰        | 15/79 [00:16<01:11,  1.11s/batch][A
Testing:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:22<01:05,  1.11s/batch][A
Testing:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:27<00:59,  1.10s/batch][A
Testing:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:33<00:54,  1.10s/batch][A
Testing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:38<00:48,  1.10s/batch][A
Testing:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:44<00:42,  1.10s/batch][A
Testing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [00:49<00:37,  1.10s/batch][A
Testing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [00:55<00:31,  1.10s/batch][A
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:00<00:26,  1.10s/batch][A
Testing:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:06<00:20,  1.10s/batch][A
Testing:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:11<00:15,  1.10s/batch][A
Testing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:17<00:09,  1.10s/batch][A
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:22<00:04,  1.10s/batch][ATesting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [01:26<00:00,  1.10s/batch]
[25/05/16 10:18:13] [train_TET.py:  177]: Test set Accuracy: 28.7
Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [7:30:06<7:39:12, 272.80s/epoch]
Model did not improve (eval acc: 28.7, best: 29.06,20/20 in a row)
Early stop after 20 epochs

JOB STATISTICS
==============
Job ID: 11880567
Cluster: snellius
User/Group: scur2578/scur2578
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 5-15:11:06 core-walltime
Job Wall-clock time: 07:30:37
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
