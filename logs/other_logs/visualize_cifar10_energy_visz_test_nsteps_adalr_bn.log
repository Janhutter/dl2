[25/05/22 22:10:19] [utils.py:   82]: PyTorch Version: torch=2.5.0+cu124, cuda=12.4, cudnn=90100
[25/05/22 22:10:19] [utils.py:   83]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  IMG_SIZE: 32
  NUM_CHANNEL: 3
  NUM_CLASSES: 10
  NUM_EX: 10000
  SEVERITY: [5, 4, 3, 2, 1]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: /scratch-shared/tea2/cifar10
DESC: 
EARLY_STOP_BEGIN: 70
EARLY_STOP_PATIENCE: 30
EATA:
  D_MARGIN: 0.05
  E_MARGIN: 2.763102111592855
  FISHER_ALPHA: 2000.0
  FISHER_SIZE: 2000
  USE_FISHER: False
EBM:
  BUFFER_SIZE: 1000
  REINIT_FREQ: 0.05
  SGLD_LR: 0.1
  SGLD_STD: 0.01
  STEPS: 40
  UNCOND: cond
LOG_DEST: energy_visz_test_bn_adam-2-0.0005-512_cond-40-0.1-0.01-1000-0.05_250522-221019.txt
LOG_TIME: 250522-221019
MODEL:
  ADAPTATION: energy
  ADA_PARAM: ['bn']
  ARCH: WRN2810_BN
  CHECKPOINT_PTH: None
  EPISODIC: False
OPTIM:
  BATCH_SIZE: 512
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LAMBDA_CLS: 1.0
  LAMBDA_ENERGY: 1.0
  LR: 0.0005
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  N_EPOCHS: 10
  SCHEDULER_GAMMA: 0.2
  SCHEDULER_MILESTONES: [60, 120, 160]
  STEPS: 2
  TEST_BATCH_SIZE: 128
  WARMUP_START_LR: 1e-06
  WARMUP_STEPS: 40
  WD: 0.0
OPTIM_ENERGY:
  BATCH_SIZE: 128
  BETA: 0.9
  CLIP_NORM: False
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
PL:
  ALPHA: 0.1
  THRESHOLD: 0.9
RNG_SEED: 1
SAR:
  MARGIN_E0: 2.763102111592855
SAVE_DIR: ./save/cifar10/bn-wrn-28-10
SHOT:
  CLF_COEFF: 0.1
  THRESHOLD: 0.9
TEST:
  
wandb: Currently logged in as: janhutter (jan-hutter) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/home5/jhutter/dl2/wandb/run-20250522_221020-zmpib71m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visz-n_steps-explr-bn-
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jan-hutter/TET
wandb: üöÄ View run at https://wandb.ai/jan-hutter/TET/runs/zmpib71m
/home/jhutter/.local/lib/python3.11/site-packages/robustbench/utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
[25/05/22 22:10:22] [main_visz.py:  106]: test-time adaptation: ENERGY
[25/05/22 22:10:22] [param.py:   18]: adapting weights of batch-normalization layer
[25/05/22 22:10:22] [optim.py:   82]: Warmup scheduler configured: 40 steps, start_lr: 1e-06, target_lr: 0.0005
[25/05/22 22:10:22] [setada.py:  167]: model for adaptation: WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=10, bias=True)
)
[25/05/22 22:10:22] [setada.py:  168]: params for adaptation: ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn2.weight', 'block1.layer.0.bn2.bias', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn2.weight', 'block1.layer.1.bn2.bias', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn2.weight', 'block1.layer.2.bn2.bias', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn2.weight', 'block1.layer.3.bn2.bias', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn2.weight', 'block2.layer.0.bn2.bias', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn2.weight', 'block2.layer.1.bn2.bias', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn2.weight', 'block2.layer.2.bn2.bias', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn2.weight', 'block2.layer.3.bn2.bias', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn2.weight', 'block3.layer.0.bn2.bias', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn2.weight', 'block3.layer.1.bn2.bias', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn2.weight', 'block3.layer.2.bn2.bias', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn2.weight', 'block3.layer.3.bn2.bias', 'bn1.weight', 'bn1.bias']
[25/05/22 22:10:22] [setada.py:  169]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0.0
)
[25/05/22 22:10:22] [eval_visz.py:  115]: not resetting model
[25/05/22 22:10:36] [eval_visz.py:   49]: batch_counter=0
[25/05/22 22:10:45] [optim.py:   58]: Warmup step 1/40, LR: 0.000013
[25/05/22 22:10:49] [eval_visz.py:   65]: batch_acc: 0.931640625
[25/05/22 22:10:49] [eval_visz.py:   49]: batch_counter=1
[25/05/22 22:10:56] [optim.py:   58]: Warmup step 2/40, LR: 0.000026
[25/05/22 22:11:00] [eval_visz.py:   65]: batch_acc: 0.953125
[25/05/22 22:11:00] [eval_visz.py:   49]: batch_counter=2
[25/05/22 22:11:07] [optim.py:   58]: Warmup step 3/40, LR: 0.000038
[25/05/22 22:11:11] [eval_visz.py:   65]: batch_acc: 0.923828125
[25/05/22 22:11:11] [eval_visz.py:   49]: batch_counter=3
[25/05/22 22:11:18] [optim.py:   58]: Warmup step 4/40, LR: 0.000051
[25/05/22 22:11:22] [eval_visz.py:   65]: batch_acc: 0.93359375
[25/05/22 22:11:22] [eval_visz.py:   49]: batch_counter=4
[25/05/22 22:11:29] [optim.py:   58]: Warmup step 5/40, LR: 0.000063
[25/05/22 22:11:33] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:11:33] [eval_visz.py:   49]: batch_counter=5
[25/05/22 22:11:40] [optim.py:   58]: Warmup step 6/40, LR: 0.000076
[25/05/22 22:11:44] [eval_visz.py:   65]: batch_acc: 0.931640625
[25/05/22 22:11:44] [eval_visz.py:   49]: batch_counter=6
[25/05/22 22:11:51] [optim.py:   58]: Warmup step 7/40, LR: 0.000088
[25/05/22 22:11:55] [eval_visz.py:   65]: batch_acc: 0.958984375
[25/05/22 22:11:55] [eval_visz.py:   49]: batch_counter=7
[25/05/22 22:12:02] [optim.py:   58]: Warmup step 8/40, LR: 0.000101
[25/05/22 22:12:06] [eval_visz.py:   65]: batch_acc: 0.939453125
[25/05/22 22:12:06] [eval_visz.py:   49]: batch_counter=8
[25/05/22 22:12:13] [optim.py:   58]: Warmup step 9/40, LR: 0.000113
[25/05/22 22:12:17] [eval_visz.py:   65]: batch_acc: 0.939453125
[25/05/22 22:12:17] [eval_visz.py:   49]: batch_counter=9
[25/05/22 22:12:24] [optim.py:   58]: Warmup step 10/40, LR: 0.000126
[25/05/22 22:12:28] [eval_visz.py:   65]: batch_acc: 0.951171875
[25/05/22 22:12:28] [eval_visz.py:   49]: batch_counter=10
[25/05/22 22:12:36] [optim.py:   58]: Warmup step 11/40, LR: 0.000138
[25/05/22 22:12:39] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:12:39] [eval_visz.py:   49]: batch_counter=11
[25/05/22 22:12:47] [optim.py:   58]: Warmup step 12/40, LR: 0.000151
[25/05/22 22:12:50] [eval_visz.py:   65]: batch_acc: 0.923828125
[25/05/22 22:12:50] [eval_visz.py:   49]: batch_counter=12
[25/05/22 22:12:58] [optim.py:   58]: Warmup step 13/40, LR: 0.000163
[25/05/22 22:13:01] [eval_visz.py:   65]: batch_acc: 0.9609375
[25/05/22 22:13:01] [eval_visz.py:   49]: batch_counter=13
[25/05/22 22:13:09] [optim.py:   58]: Warmup step 14/40, LR: 0.000176
[25/05/22 22:13:12] [eval_visz.py:   65]: batch_acc: 0.955078125
[25/05/22 22:13:12] [eval_visz.py:   49]: batch_counter=14
[25/05/22 22:13:20] [optim.py:   58]: Warmup step 15/40, LR: 0.000188
[25/05/22 22:13:23] [eval_visz.py:   65]: batch_acc: 0.916015625
[25/05/22 22:13:23] [eval_visz.py:   49]: batch_counter=15
[25/05/22 22:13:31] [optim.py:   58]: Warmup step 16/40, LR: 0.000201
[25/05/22 22:13:35] [eval_visz.py:   65]: batch_acc: 0.95703125
[25/05/22 22:13:35] [eval_visz.py:   49]: batch_counter=16
[25/05/22 22:13:42] [optim.py:   58]: Warmup step 17/40, LR: 0.000213
[25/05/22 22:13:46] [eval_visz.py:   65]: batch_acc: 0.94921875
[25/05/22 22:13:46] [eval_visz.py:   49]: batch_counter=17
[25/05/22 22:13:53] [optim.py:   58]: Warmup step 18/40, LR: 0.000226
[25/05/22 22:13:57] [eval_visz.py:   65]: batch_acc: 0.94921875
[25/05/22 22:13:57] [eval_visz.py:   49]: batch_counter=18
[25/05/22 22:14:04] [optim.py:   58]: Warmup step 19/40, LR: 0.000238
[25/05/22 22:14:08] [eval_visz.py:   65]: batch_acc: 0.94921875
[25/05/22 22:14:08] [eval_visz.py:   49]: batch_counter=19
[25/05/22 22:14:13] [optim.py:   58]: Warmup step 20/40, LR: 0.000251
[25/05/22 22:14:16] [eval_visz.py:   65]: batch_acc: 0.9522058963775635
[25/05/22 22:14:16] [eval_visz.py:   49]: batch_counter=0
[25/05/22 22:14:24] [optim.py:   58]: Warmup step 21/40, LR: 0.000263
[25/05/22 22:14:35] [optim.py:   58]: Warmup step 22/40, LR: 0.000275
[25/05/22 22:14:38] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:14:38] [eval_visz.py:   49]: batch_counter=1
[25/05/22 22:14:45] [optim.py:   58]: Warmup step 23/40, LR: 0.000288
[25/05/22 22:14:57] [optim.py:   58]: Warmup step 24/40, LR: 0.000300
[25/05/22 22:15:00] [eval_visz.py:   65]: batch_acc: 0.9453125
[25/05/22 22:15:00] [eval_visz.py:   49]: batch_counter=2
[25/05/22 22:15:07] [optim.py:   58]: Warmup step 25/40, LR: 0.000313
[25/05/22 22:15:18] [optim.py:   58]: Warmup step 26/40, LR: 0.000325
[25/05/22 22:15:21] [eval_visz.py:   65]: batch_acc: 0.95703125
[25/05/22 22:15:21] [eval_visz.py:   49]: batch_counter=3
[25/05/22 22:15:29] [optim.py:   58]: Warmup step 27/40, LR: 0.000338
[25/05/22 22:15:40] [optim.py:   58]: Warmup step 28/40, LR: 0.000350
[25/05/22 22:15:43] [eval_visz.py:   65]: batch_acc: 0.939453125
[25/05/22 22:15:43] [eval_visz.py:   49]: batch_counter=4
[25/05/22 22:15:50] [optim.py:   58]: Warmup step 29/40, LR: 0.000363
[25/05/22 22:16:01] [optim.py:   58]: Warmup step 30/40, LR: 0.000375
[25/05/22 22:16:04] [eval_visz.py:   65]: batch_acc: 0.958984375
[25/05/22 22:16:04] [eval_visz.py:   49]: batch_counter=5
[25/05/22 22:16:12] [optim.py:   58]: Warmup step 31/40, LR: 0.000388
[25/05/22 22:16:23] [optim.py:   58]: Warmup step 32/40, LR: 0.000400
[25/05/22 22:16:26] [eval_visz.py:   65]: batch_acc: 0.927734375
[25/05/22 22:16:26] [eval_visz.py:   49]: batch_counter=6
[25/05/22 22:16:33] [optim.py:   58]: Warmup step 33/40, LR: 0.000413
[25/05/22 22:16:44] [optim.py:   58]: Warmup step 34/40, LR: 0.000425
[25/05/22 22:16:47] [eval_visz.py:   65]: batch_acc: 0.939453125
[25/05/22 22:16:47] [eval_visz.py:   49]: batch_counter=7
[25/05/22 22:16:55] [optim.py:   58]: Warmup step 35/40, LR: 0.000438
[25/05/22 22:17:06] [optim.py:   58]: Warmup step 36/40, LR: 0.000450
[25/05/22 22:17:09] [eval_visz.py:   65]: batch_acc: 0.939453125
[25/05/22 22:17:09] [eval_visz.py:   49]: batch_counter=8
[25/05/22 22:17:16] [optim.py:   58]: Warmup step 37/40, LR: 0.000463
[25/05/22 22:17:27] [optim.py:   58]: Warmup step 38/40, LR: 0.000475
[25/05/22 22:17:30] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:17:30] [eval_visz.py:   49]: batch_counter=9
[25/05/22 22:17:38] [optim.py:   58]: Warmup step 39/40, LR: 0.000488
[25/05/22 22:17:49] [optim.py:   58]: Warmup step 40/40, LR: 0.000500
[25/05/22 22:17:52] [eval_visz.py:   65]: batch_acc: 0.966796875
[25/05/22 22:17:52] [eval_visz.py:   49]: batch_counter=10
[25/05/22 22:17:59] [optim.py:   72]: step 1, LR: 0.000495
[25/05/22 22:18:11] [optim.py:   72]: step 2, LR: 0.000490
[25/05/22 22:18:14] [eval_visz.py:   65]: batch_acc: 0.943359375
[25/05/22 22:18:14] [eval_visz.py:   49]: batch_counter=11
[25/05/22 22:18:21] [optim.py:   72]: step 3, LR: 0.000485
[25/05/22 22:18:32] [optim.py:   72]: step 4, LR: 0.000480
[25/05/22 22:18:35] [eval_visz.py:   65]: batch_acc: 0.93359375
[25/05/22 22:18:35] [eval_visz.py:   49]: batch_counter=12
[25/05/22 22:18:43] [optim.py:   72]: step 5, LR: 0.000475
[25/05/22 22:18:54] [optim.py:   72]: step 6, LR: 0.000471
[25/05/22 22:18:57] [eval_visz.py:   65]: batch_acc: 0.92578125
[25/05/22 22:18:57] [eval_visz.py:   49]: batch_counter=13
[25/05/22 22:19:04] [optim.py:   72]: step 7, LR: 0.000466
[25/05/22 22:19:15] [optim.py:   72]: step 8, LR: 0.000461
[25/05/22 22:19:18] [eval_visz.py:   65]: batch_acc: 0.953125
[25/05/22 22:19:18] [eval_visz.py:   49]: batch_counter=14
[25/05/22 22:19:26] [optim.py:   72]: step 9, LR: 0.000457
[25/05/22 22:19:37] [optim.py:   72]: step 10, LR: 0.000452
[25/05/22 22:19:40] [eval_visz.py:   65]: batch_acc: 0.9453125
[25/05/22 22:19:40] [eval_visz.py:   49]: batch_counter=15
[25/05/22 22:19:47] [optim.py:   72]: step 11, LR: 0.000448
[25/05/22 22:19:59] [optim.py:   72]: step 12, LR: 0.000443
[25/05/22 22:20:02] [eval_visz.py:   65]: batch_acc: 0.947265625
[25/05/22 22:20:02] [eval_visz.py:   49]: batch_counter=16
[25/05/22 22:20:09] [optim.py:   72]: step 13, LR: 0.000439
[25/05/22 22:20:20] [optim.py:   72]: step 14, LR: 0.000434
[25/05/22 22:20:23] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:20:23] [eval_visz.py:   49]: batch_counter=17
[25/05/22 22:20:31] [optim.py:   72]: step 15, LR: 0.000430
[25/05/22 22:20:42] [optim.py:   72]: step 16, LR: 0.000426
[25/05/22 22:20:45] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:20:45] [eval_visz.py:   49]: batch_counter=18
[25/05/22 22:20:52] [optim.py:   72]: step 17, LR: 0.000421
[25/05/22 22:21:03] [optim.py:   72]: step 18, LR: 0.000417
[25/05/22 22:21:06] [eval_visz.py:   65]: batch_acc: 0.95703125
[25/05/22 22:21:06] [eval_visz.py:   49]: batch_counter=19
[25/05/22 22:21:10] [optim.py:   72]: step 19, LR: 0.000413
[25/05/22 22:21:18] [optim.py:   72]: step 20, LR: 0.000409
[25/05/22 22:21:21] [eval_visz.py:   65]: batch_acc: 0.9448529481887817
[25/05/22 22:21:21] [eval_visz.py:   49]: batch_counter=0
[25/05/22 22:21:29] [optim.py:   72]: step 21, LR: 0.000405
[25/05/22 22:21:40] [optim.py:   72]: step 22, LR: 0.000401
[25/05/22 22:21:43] [eval_visz.py:   65]: batch_acc: 0.9453125
[25/05/22 22:21:43] [eval_visz.py:   49]: batch_counter=1
[25/05/22 22:21:50] [optim.py:   72]: step 23, LR: 0.000397
[25/05/22 22:22:01] [optim.py:   72]: step 24, LR: 0.000393
[25/05/22 22:22:04] [eval_visz.py:   65]: batch_acc: 0.947265625
[25/05/22 22:22:04] [eval_visz.py:   49]: batch_counter=2
[25/05/22 22:22:12] [optim.py:   72]: step 25, LR: 0.000389
[25/05/22 22:22:23] [optim.py:   72]: step 26, LR: 0.000385
[25/05/22 22:22:26] [eval_visz.py:   65]: batch_acc: 0.955078125
[25/05/22 22:22:26] [eval_visz.py:   49]: batch_counter=3
[25/05/22 22:22:33] [optim.py:   72]: step 27, LR: 0.000381
[25/05/22 22:22:45] [optim.py:   72]: step 28, LR: 0.000377
[25/05/22 22:22:48] [eval_visz.py:   65]: batch_acc: 0.962890625
[25/05/22 22:22:48] [eval_visz.py:   49]: batch_counter=4
[25/05/22 22:22:55] [optim.py:   72]: step 29, LR: 0.000374
[25/05/22 22:23:06] [optim.py:   72]: step 30, LR: 0.000370
[25/05/22 22:23:09] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:23:09] [eval_visz.py:   49]: batch_counter=5
[25/05/22 22:23:17] [optim.py:   72]: step 31, LR: 0.000366
[25/05/22 22:23:28] [optim.py:   72]: step 32, LR: 0.000362
[25/05/22 22:23:31] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:23:31] [eval_visz.py:   49]: batch_counter=6
[25/05/22 22:23:38] [optim.py:   72]: step 33, LR: 0.000359
[25/05/22 22:23:49] [optim.py:   72]: step 34, LR: 0.000355
[25/05/22 22:23:52] [eval_visz.py:   65]: batch_acc: 0.931640625
[25/05/22 22:23:52] [eval_visz.py:   49]: batch_counter=7
[25/05/22 22:24:00] [optim.py:   72]: step 35, LR: 0.000352
[25/05/22 22:24:11] [optim.py:   72]: step 36, LR: 0.000348
[25/05/22 22:24:14] [eval_visz.py:   65]: batch_acc: 0.953125
[25/05/22 22:24:14] [eval_visz.py:   49]: batch_counter=8
[25/05/22 22:24:21] [optim.py:   72]: step 37, LR: 0.000345
[25/05/22 22:24:33] [optim.py:   72]: step 38, LR: 0.000341
[25/05/22 22:24:36] [eval_visz.py:   65]: batch_acc: 0.935546875
[25/05/22 22:24:36] [eval_visz.py:   49]: batch_counter=9
[25/05/22 22:24:43] [optim.py:   72]: step 39, LR: 0.000338
[25/05/22 22:24:54] [optim.py:   72]: step 40, LR: 0.000334
[25/05/22 22:24:57] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:24:57] [eval_visz.py:   49]: batch_counter=10
[25/05/22 22:25:05] [optim.py:   72]: step 41, LR: 0.000331
[25/05/22 22:25:16] [optim.py:   72]: step 42, LR: 0.000328
[25/05/22 22:25:19] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:25:19] [eval_visz.py:   49]: batch_counter=11
[25/05/22 22:25:26] [optim.py:   72]: step 43, LR: 0.000325
[25/05/22 22:25:37] [optim.py:   72]: step 44, LR: 0.000321
[25/05/22 22:25:41] [eval_visz.py:   65]: batch_acc: 0.943359375
[25/05/22 22:25:41] [eval_visz.py:   49]: batch_counter=12
[25/05/22 22:25:48] [optim.py:   72]: step 45, LR: 0.000318
[25/05/22 22:25:59] [optim.py:   72]: step 46, LR: 0.000315
[25/05/22 22:26:02] [eval_visz.py:   65]: batch_acc: 0.955078125
[25/05/22 22:26:02] [eval_visz.py:   49]: batch_counter=13
[25/05/22 22:26:10] [optim.py:   72]: step 47, LR: 0.000312
[25/05/22 22:26:21] [optim.py:   72]: step 48, LR: 0.000309
[25/05/22 22:26:24] [eval_visz.py:   65]: batch_acc: 0.951171875
[25/05/22 22:26:24] [eval_visz.py:   49]: batch_counter=14
[25/05/22 22:26:31] [optim.py:   72]: step 49, LR: 0.000306
[25/05/22 22:26:42] [optim.py:   72]: step 50, LR: 0.000303
[25/05/22 22:26:45] [eval_visz.py:   65]: batch_acc: 0.916015625
[25/05/22 22:26:45] [eval_visz.py:   49]: batch_counter=15
[25/05/22 22:26:53] [optim.py:   72]: step 51, LR: 0.000299
[25/05/22 22:27:04] [optim.py:   72]: step 52, LR: 0.000296
[25/05/22 22:27:07] [eval_visz.py:   65]: batch_acc: 0.9296875
[25/05/22 22:27:07] [eval_visz.py:   49]: batch_counter=16
[25/05/22 22:27:14] [optim.py:   72]: step 53, LR: 0.000294
[25/05/22 22:27:25] [optim.py:   72]: step 54, LR: 0.000291
[25/05/22 22:27:29] [eval_visz.py:   65]: batch_acc: 0.9140625
[25/05/22 22:27:29] [eval_visz.py:   49]: batch_counter=17
[25/05/22 22:27:36] [optim.py:   72]: step 55, LR: 0.000288
[25/05/22 22:27:47] [optim.py:   72]: step 56, LR: 0.000285
[25/05/22 22:27:50] [eval_visz.py:   65]: batch_acc: 0.9609375
[25/05/22 22:27:50] [eval_visz.py:   49]: batch_counter=18
[25/05/22 22:27:58] [optim.py:   72]: step 57, LR: 0.000282
[25/05/22 22:28:09] [optim.py:   72]: step 58, LR: 0.000279
[25/05/22 22:28:12] [eval_visz.py:   65]: batch_acc: 0.935546875
[25/05/22 22:28:12] [eval_visz.py:   49]: batch_counter=19
[25/05/22 22:28:16] [optim.py:   72]: step 59, LR: 0.000276
[25/05/22 22:28:23] [optim.py:   72]: step 60, LR: 0.000274
[25/05/22 22:28:26] [eval_visz.py:   65]: batch_acc: 0.9448529481887817
[25/05/22 22:28:26] [eval_visz.py:   49]: batch_counter=0
[25/05/22 22:28:34] [optim.py:   72]: step 61, LR: 0.000271
[25/05/22 22:28:45] [optim.py:   72]: step 62, LR: 0.000268
[25/05/22 22:28:55] [optim.py:   72]: step 63, LR: 0.000265
[25/05/22 22:28:59] [eval_visz.py:   65]: batch_acc: 0.923828125
[25/05/22 22:28:59] [eval_visz.py:   49]: batch_counter=1
[25/05/22 22:29:06] [optim.py:   72]: step 64, LR: 0.000263
[25/05/22 22:29:17] [optim.py:   72]: step 65, LR: 0.000260
[25/05/22 22:29:28] [optim.py:   72]: step 66, LR: 0.000258
[25/05/22 22:29:31] [eval_visz.py:   65]: batch_acc: 0.947265625
[25/05/22 22:29:31] [eval_visz.py:   49]: batch_counter=2
[25/05/22 22:29:38] [optim.py:   72]: step 67, LR: 0.000255
[25/05/22 22:29:49] [optim.py:   72]: step 68, LR: 0.000252
[25/05/22 22:30:00] [optim.py:   72]: step 69, LR: 0.000250
[25/05/22 22:30:03] [eval_visz.py:   65]: batch_acc: 0.9609375
[25/05/22 22:30:03] [eval_visz.py:   49]: batch_counter=3
[25/05/22 22:30:10] [optim.py:   72]: step 70, LR: 0.000247
[25/05/22 22:30:21] [optim.py:   72]: step 71, LR: 0.000245
[25/05/22 22:30:32] [optim.py:   72]: step 72, LR: 0.000242
[25/05/22 22:30:35] [eval_visz.py:   65]: batch_acc: 0.955078125
[25/05/22 22:30:35] [eval_visz.py:   49]: batch_counter=4
[25/05/22 22:30:42] [optim.py:   72]: step 73, LR: 0.000240
[25/05/22 22:30:54] [optim.py:   72]: step 74, LR: 0.000238
[25/05/22 22:31:04] [optim.py:   72]: step 75, LR: 0.000235
[25/05/22 22:31:07] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:31:07] [eval_visz.py:   49]: batch_counter=5
[25/05/22 22:31:15] [optim.py:   72]: step 76, LR: 0.000233
[25/05/22 22:31:26] [optim.py:   72]: step 77, LR: 0.000231
[25/05/22 22:31:36] [optim.py:   72]: step 78, LR: 0.000228
[25/05/22 22:31:39] [eval_visz.py:   65]: batch_acc: 0.93359375
[25/05/22 22:31:39] [eval_visz.py:   49]: batch_counter=6
[25/05/22 22:31:47] [optim.py:   72]: step 79, LR: 0.000226
[25/05/22 22:31:58] [optim.py:   72]: step 80, LR: 0.000224
[25/05/22 22:32:08] [optim.py:   72]: step 81, LR: 0.000222
[25/05/22 22:32:11] [eval_visz.py:   65]: batch_acc: 0.927734375
[25/05/22 22:32:11] [eval_visz.py:   49]: batch_counter=7
[25/05/22 22:32:19] [optim.py:   72]: step 82, LR: 0.000219
[25/05/22 22:32:30] [optim.py:   72]: step 83, LR: 0.000217
[25/05/22 22:32:40] [optim.py:   72]: step 84, LR: 0.000215
[25/05/22 22:32:44] [eval_visz.py:   65]: batch_acc: 0.9609375
[25/05/22 22:32:44] [eval_visz.py:   49]: batch_counter=8
[25/05/22 22:32:51] [optim.py:   72]: step 85, LR: 0.000213
[25/05/22 22:33:02] [optim.py:   72]: step 86, LR: 0.000211
[25/05/22 22:33:13] [optim.py:   72]: step 87, LR: 0.000209
[25/05/22 22:33:16] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:33:16] [eval_visz.py:   49]: batch_counter=9
[25/05/22 22:33:23] [optim.py:   72]: step 88, LR: 0.000206
[25/05/22 22:33:34] [optim.py:   72]: step 89, LR: 0.000204
[25/05/22 22:33:45] [optim.py:   72]: step 90, LR: 0.000202
[25/05/22 22:33:48] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:33:48] [eval_visz.py:   49]: batch_counter=10
[25/05/22 22:33:55] [optim.py:   72]: step 91, LR: 0.000200
[25/05/22 22:34:06] [optim.py:   72]: step 92, LR: 0.000198
[25/05/22 22:34:17] [optim.py:   72]: step 93, LR: 0.000196
[25/05/22 22:34:20] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:34:20] [eval_visz.py:   49]: batch_counter=11
[25/05/22 22:34:27] [optim.py:   72]: step 94, LR: 0.000194
[25/05/22 22:34:38] [optim.py:   72]: step 95, LR: 0.000192
[25/05/22 22:34:49] [optim.py:   72]: step 96, LR: 0.000191
[25/05/22 22:34:52] [eval_visz.py:   65]: batch_acc: 0.943359375
[25/05/22 22:34:52] [eval_visz.py:   49]: batch_counter=12
[25/05/22 22:34:59] [optim.py:   72]: step 97, LR: 0.000189
[25/05/22 22:35:11] [optim.py:   72]: step 98, LR: 0.000187
[25/05/22 22:35:21] [optim.py:   72]: step 99, LR: 0.000185
[25/05/22 22:35:24] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:35:24] [eval_visz.py:   49]: batch_counter=13
[25/05/22 22:35:32] [optim.py:   72]: step 100, LR: 0.000183
[25/05/22 22:35:43] [optim.py:   72]: step 101, LR: 0.000181
[25/05/22 22:35:53] [optim.py:   72]: step 102, LR: 0.000179
[25/05/22 22:35:56] [eval_visz.py:   65]: batch_acc: 0.93359375
[25/05/22 22:35:56] [eval_visz.py:   49]: batch_counter=14
[25/05/22 22:36:04] [optim.py:   72]: step 103, LR: 0.000178
[25/05/22 22:36:15] [optim.py:   72]: step 104, LR: 0.000176
[25/05/22 22:36:25] [optim.py:   72]: step 105, LR: 0.000174
[25/05/22 22:36:29] [eval_visz.py:   65]: batch_acc: 0.9453125
[25/05/22 22:36:29] [eval_visz.py:   49]: batch_counter=15
[25/05/22 22:36:36] [optim.py:   72]: step 106, LR: 0.000172
[25/05/22 22:36:47] [optim.py:   72]: step 107, LR: 0.000171
[25/05/22 22:36:58] [optim.py:   72]: step 108, LR: 0.000169
[25/05/22 22:37:01] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:37:01] [eval_visz.py:   49]: batch_counter=16
[25/05/22 22:37:08] [optim.py:   72]: step 109, LR: 0.000167
[25/05/22 22:37:19] [optim.py:   72]: step 110, LR: 0.000166
[25/05/22 22:37:30] [optim.py:   72]: step 111, LR: 0.000164
[25/05/22 22:37:33] [eval_visz.py:   65]: batch_acc: 0.93359375
[25/05/22 22:37:33] [eval_visz.py:   49]: batch_counter=17
[25/05/22 22:37:40] [optim.py:   72]: step 112, LR: 0.000162
[25/05/22 22:37:51] [optim.py:   72]: step 113, LR: 0.000161
[25/05/22 22:38:02] [optim.py:   72]: step 114, LR: 0.000159
[25/05/22 22:38:05] [eval_visz.py:   65]: batch_acc: 0.947265625
[25/05/22 22:38:05] [eval_visz.py:   49]: batch_counter=18
[25/05/22 22:38:12] [optim.py:   72]: step 115, LR: 0.000157
[25/05/22 22:38:24] [optim.py:   72]: step 116, LR: 0.000156
[25/05/22 22:38:34] [optim.py:   72]: step 117, LR: 0.000154
[25/05/22 22:38:37] [eval_visz.py:   65]: batch_acc: 0.93359375
[25/05/22 22:38:37] [eval_visz.py:   49]: batch_counter=19
[25/05/22 22:38:41] [optim.py:   72]: step 118, LR: 0.000153
[25/05/22 22:38:49] [optim.py:   72]: step 119, LR: 0.000151
[25/05/22 22:38:56] [optim.py:   72]: step 120, LR: 0.000150
[25/05/22 22:38:59] [eval_visz.py:   65]: batch_acc: 0.9227941036224365
[25/05/22 22:38:59] [eval_visz.py:   49]: batch_counter=0
[25/05/22 22:39:06] [optim.py:   72]: step 121, LR: 0.000148
[25/05/22 22:39:17] [optim.py:   72]: step 122, LR: 0.000147
[25/05/22 22:39:28] [optim.py:   72]: step 123, LR: 0.000145
[25/05/22 22:39:31] [eval_visz.py:   65]: batch_acc: 0.94921875
[25/05/22 22:39:31] [eval_visz.py:   49]: batch_counter=1
[25/05/22 22:39:38] [optim.py:   72]: step 124, LR: 0.000144
[25/05/22 22:39:50] [optim.py:   72]: step 125, LR: 0.000142
[25/05/22 22:40:00] [optim.py:   72]: step 126, LR: 0.000141
[25/05/22 22:40:03] [eval_visz.py:   65]: batch_acc: 0.951171875
[25/05/22 22:40:03] [eval_visz.py:   49]: batch_counter=2
[25/05/22 22:40:11] [optim.py:   72]: step 127, LR: 0.000140
[25/05/22 22:40:22] [optim.py:   72]: step 128, LR: 0.000138
[25/05/22 22:40:32] [optim.py:   72]: step 129, LR: 0.000137
[25/05/22 22:40:35] [eval_visz.py:   65]: batch_acc: 0.931640625
[25/05/22 22:40:35] [eval_visz.py:   49]: batch_counter=3
[25/05/22 22:40:43] [optim.py:   72]: step 130, LR: 0.000135
[25/05/22 22:40:54] [optim.py:   72]: step 131, LR: 0.000134
[25/05/22 22:41:04] [optim.py:   72]: step 132, LR: 0.000133
[25/05/22 22:41:08] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:41:08] [eval_visz.py:   49]: batch_counter=4
[25/05/22 22:41:15] [optim.py:   72]: step 133, LR: 0.000131
[25/05/22 22:41:26] [optim.py:   72]: step 134, LR: 0.000130
[25/05/22 22:41:37] [optim.py:   72]: step 135, LR: 0.000129
[25/05/22 22:41:40] [eval_visz.py:   65]: batch_acc: 0.935546875
[25/05/22 22:41:40] [eval_visz.py:   49]: batch_counter=5
[25/05/22 22:41:47] [optim.py:   72]: step 136, LR: 0.000127
[25/05/22 22:41:58] [optim.py:   72]: step 137, LR: 0.000126
[25/05/22 22:42:09] [optim.py:   72]: step 138, LR: 0.000125
[25/05/22 22:42:12] [eval_visz.py:   65]: batch_acc: 0.9296875
[25/05/22 22:42:12] [eval_visz.py:   49]: batch_counter=6
[25/05/22 22:42:19] [optim.py:   72]: step 139, LR: 0.000124
[25/05/22 22:42:30] [optim.py:   72]: step 140, LR: 0.000122
[25/05/22 22:42:41] [optim.py:   72]: step 141, LR: 0.000121
[25/05/22 22:42:44] [eval_visz.py:   65]: batch_acc: 0.9296875
[25/05/22 22:42:44] [eval_visz.py:   49]: batch_counter=7
[25/05/22 22:42:51] [optim.py:   72]: step 142, LR: 0.000120
[25/05/22 22:43:02] [optim.py:   72]: step 143, LR: 0.000119
[25/05/22 22:43:13] [optim.py:   72]: step 144, LR: 0.000118
[25/05/22 22:43:16] [eval_visz.py:   65]: batch_acc: 0.9453125
[25/05/22 22:43:16] [eval_visz.py:   49]: batch_counter=8
[25/05/22 22:43:23] [optim.py:   72]: step 145, LR: 0.000116
[25/05/22 22:43:35] [optim.py:   72]: step 146, LR: 0.000115
[25/05/22 22:43:45] [optim.py:   72]: step 147, LR: 0.000114
[25/05/22 22:43:48] [eval_visz.py:   65]: batch_acc: 0.935546875
[25/05/22 22:43:48] [eval_visz.py:   49]: batch_counter=9
[25/05/22 22:43:56] [optim.py:   72]: step 148, LR: 0.000113
[25/05/22 22:44:07] [optim.py:   72]: step 149, LR: 0.000112
[25/05/22 22:44:17] [optim.py:   72]: step 150, LR: 0.000111
[25/05/22 22:44:20] [eval_visz.py:   65]: batch_acc: 0.93359375
[25/05/22 22:44:20] [eval_visz.py:   49]: batch_counter=10
[25/05/22 22:44:28] [optim.py:   72]: step 151, LR: 0.000110
[25/05/22 22:44:39] [optim.py:   72]: step 152, LR: 0.000109
[25/05/22 22:44:49] [optim.py:   72]: step 153, LR: 0.000107
[25/05/22 22:44:52] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:44:52] [eval_visz.py:   49]: batch_counter=11
[25/05/22 22:45:00] [optim.py:   72]: step 154, LR: 0.000106
[25/05/22 22:45:11] [optim.py:   72]: step 155, LR: 0.000105
[25/05/22 22:45:22] [optim.py:   72]: step 156, LR: 0.000104
[25/05/22 22:45:25] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:45:25] [eval_visz.py:   49]: batch_counter=12
[25/05/22 22:45:32] [optim.py:   72]: step 157, LR: 0.000103
[25/05/22 22:45:43] [optim.py:   72]: step 158, LR: 0.000102
[25/05/22 22:45:54] [optim.py:   72]: step 159, LR: 0.000101
[25/05/22 22:45:57] [eval_visz.py:   65]: batch_acc: 0.9296875
[25/05/22 22:45:57] [eval_visz.py:   49]: batch_counter=13
[25/05/22 22:46:04] [optim.py:   72]: step 160, LR: 0.000100
[25/05/22 22:46:15] [optim.py:   72]: step 161, LR: 0.000099
[25/05/22 22:46:26] [optim.py:   72]: step 162, LR: 0.000098
[25/05/22 22:46:29] [eval_visz.py:   65]: batch_acc: 0.96875
[25/05/22 22:46:29] [eval_visz.py:   49]: batch_counter=14
[25/05/22 22:46:36] [optim.py:   72]: step 163, LR: 0.000097
[25/05/22 22:46:47] [optim.py:   72]: step 164, LR: 0.000096
[25/05/22 22:46:58] [optim.py:   72]: step 165, LR: 0.000095
[25/05/22 22:47:01] [eval_visz.py:   65]: batch_acc: 0.93359375
[25/05/22 22:47:01] [eval_visz.py:   49]: batch_counter=15
[25/05/22 22:47:08] [optim.py:   72]: step 166, LR: 0.000094
[25/05/22 22:47:20] [optim.py:   72]: step 167, LR: 0.000093
[25/05/22 22:47:30] [optim.py:   72]: step 168, LR: 0.000092
[25/05/22 22:47:33] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:47:33] [eval_visz.py:   49]: batch_counter=16
[25/05/22 22:47:41] [optim.py:   72]: step 169, LR: 0.000091
[25/05/22 22:47:52] [optim.py:   72]: step 170, LR: 0.000091
[25/05/22 22:48:02] [optim.py:   72]: step 171, LR: 0.000090
[25/05/22 22:48:05] [eval_visz.py:   65]: batch_acc: 0.9296875
[25/05/22 22:48:05] [eval_visz.py:   49]: batch_counter=17
[25/05/22 22:48:13] [optim.py:   72]: step 172, LR: 0.000089
[25/05/22 22:48:24] [optim.py:   72]: step 173, LR: 0.000088
[25/05/22 22:48:34] [optim.py:   72]: step 174, LR: 0.000087
[25/05/22 22:48:38] [eval_visz.py:   65]: batch_acc: 0.923828125
[25/05/22 22:48:38] [eval_visz.py:   49]: batch_counter=18
[25/05/22 22:48:45] [optim.py:   72]: step 175, LR: 0.000086
[25/05/22 22:48:56] [optim.py:   72]: step 176, LR: 0.000085
[25/05/22 22:49:07] [optim.py:   72]: step 177, LR: 0.000084
[25/05/22 22:49:10] [eval_visz.py:   65]: batch_acc: 0.9453125
[25/05/22 22:49:10] [eval_visz.py:   49]: batch_counter=19
[25/05/22 22:49:14] [optim.py:   72]: step 178, LR: 0.000084
[25/05/22 22:49:21] [optim.py:   72]: step 179, LR: 0.000083
[25/05/22 22:49:28] [optim.py:   72]: step 180, LR: 0.000082
[25/05/22 22:49:31] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:49:31] [eval_visz.py:   49]: batch_counter=0
[25/05/22 22:49:39] [optim.py:   72]: step 181, LR: 0.000081
[25/05/22 22:49:50] [optim.py:   72]: step 182, LR: 0.000080
[25/05/22 22:50:00] [optim.py:   72]: step 183, LR: 0.000079
[25/05/22 22:50:03] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:50:03] [eval_visz.py:   49]: batch_counter=1
[25/05/22 22:50:11] [optim.py:   72]: step 184, LR: 0.000079
[25/05/22 22:50:22] [optim.py:   72]: step 185, LR: 0.000078
[25/05/22 22:50:33] [optim.py:   72]: step 186, LR: 0.000077
[25/05/22 22:50:36] [eval_visz.py:   65]: batch_acc: 0.9375
[25/05/22 22:50:36] [eval_visz.py:   49]: batch_counter=2
[25/05/22 22:50:43] [optim.py:   72]: step 187, LR: 0.000076
[25/05/22 22:50:54] [optim.py:   72]: step 188, LR: 0.000076
[25/05/22 22:51:05] [optim.py:   72]: step 189, LR: 0.000075
[25/05/22 22:51:08] [eval_visz.py:   65]: batch_acc: 0.927734375
[25/05/22 22:51:08] [eval_visz.py:   49]: batch_counter=3
[25/05/22 22:51:15] [optim.py:   72]: step 190, LR: 0.000074
[25/05/22 22:51:26] [optim.py:   72]: step 191, LR: 0.000073
[25/05/22 22:51:37] [optim.py:   72]: step 192, LR: 0.000073
[25/05/22 22:51:40] [eval_visz.py:   65]: batch_acc: 0.943359375
[25/05/22 22:51:40] [eval_visz.py:   49]: batch_counter=4
[25/05/22 22:51:47] [optim.py:   72]: step 193, LR: 0.000072
[25/05/22 22:51:58] [optim.py:   72]: step 194, LR: 0.000071
[25/05/22 22:52:09] [optim.py:   72]: step 195, LR: 0.000070
[25/05/22 22:52:12] [eval_visz.py:   65]: batch_acc: 0.951171875
[25/05/22 22:52:12] [eval_visz.py:   49]: batch_counter=5
[25/05/22 22:52:19] [optim.py:   72]: step 196, LR: 0.000070
[25/05/22 22:52:31] [optim.py:   72]: step 197, LR: 0.000069
[25/05/22 22:52:41] [optim.py:   72]: step 198, LR: 0.000068
[25/05/22 22:52:44] [eval_visz.py:   65]: batch_acc: 0.939453125
[25/05/22 22:52:44] [eval_visz.py:   49]: batch_counter=6
[25/05/22 22:52:52] [optim.py:   72]: step 199, LR: 0.000068
[25/05/22 22:53:03] [optim.py:   72]: step 200, LR: 0.000067
[25/05/22 22:53:13] [optim.py:   72]: step 201, LR: 0.000066
[25/05/22 22:53:16] [eval_visz.py:   65]: batch_acc: 0.931640625
[25/05/22 22:53:16] [eval_visz.py:   49]: batch_counter=7
[25/05/22 22:53:24] [optim.py:   72]: step 202, LR: 0.000066
[25/05/22 22:53:35] [optim.py:   72]: step 203, LR: 0.000065
[25/05/22 22:53:45] [optim.py:   72]: step 204, LR: 0.000064
[25/05/22 22:53:48] [eval_visz.py:   65]: batch_acc: 0.9296875
[25/05/22 22:53:48] [eval_visz.py:   49]: batch_counter=8
[25/05/22 22:53:56] [optim.py:   72]: step 205, LR: 0.000064
[25/05/22 22:54:07] [optim.py:   72]: step 206, LR: 0.000063
[25/05/22 22:54:17] [optim.py:   72]: step 207, LR: 0.000062
[25/05/22 22:54:21] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:54:21] [eval_visz.py:   49]: batch_counter=9
[25/05/22 22:54:28] [optim.py:   72]: step 208, LR: 0.000062
[25/05/22 22:54:39] [optim.py:   72]: step 209, LR: 0.000061
[25/05/22 22:54:50] [optim.py:   72]: step 210, LR: 0.000061
[25/05/22 22:54:53] [eval_visz.py:   65]: batch_acc: 0.93359375
[25/05/22 22:54:53] [eval_visz.py:   49]: batch_counter=10
[25/05/22 22:55:00] [optim.py:   72]: step 211, LR: 0.000060
[25/05/22 22:55:11] [optim.py:   72]: step 212, LR: 0.000059
[25/05/22 22:55:22] [optim.py:   72]: step 213, LR: 0.000059
[25/05/22 22:55:25] [eval_visz.py:   65]: batch_acc: 0.92578125
[25/05/22 22:55:25] [eval_visz.py:   49]: batch_counter=11
[25/05/22 22:55:32] [optim.py:   72]: step 214, LR: 0.000058
[25/05/22 22:55:43] [optim.py:   72]: step 215, LR: 0.000058
[25/05/22 22:55:54] [optim.py:   72]: step 216, LR: 0.000057
[25/05/22 22:55:57] [eval_visz.py:   65]: batch_acc: 0.955078125
[25/05/22 22:55:57] [eval_visz.py:   49]: batch_counter=12
[25/05/22 22:56:04] [optim.py:   72]: step 217, LR: 0.000056
[25/05/22 22:56:16] [optim.py:   72]: step 218, LR: 0.000056
[25/05/22 22:56:26] [optim.py:   72]: step 219, LR: 0.000055
[25/05/22 22:56:29] [eval_visz.py:   65]: batch_acc: 0.943359375
[25/05/22 22:56:29] [eval_visz.py:   49]: batch_counter=13
[25/05/22 22:56:37] [optim.py:   72]: step 220, LR: 0.000055
[25/05/22 22:56:48] [optim.py:   72]: step 221, LR: 0.000054
[25/05/22 22:56:58] [optim.py:   72]: step 222, LR: 0.000054
[25/05/22 22:57:01] [eval_visz.py:   65]: batch_acc: 0.962890625
[25/05/22 22:57:01] [eval_visz.py:   49]: batch_counter=14
[25/05/22 22:57:09] [optim.py:   72]: step 223, LR: 0.000053
[25/05/22 22:57:20] [optim.py:   72]: step 224, LR: 0.000053
[25/05/22 22:57:30] [optim.py:   72]: step 225, LR: 0.000052
[25/05/22 22:57:34] [eval_visz.py:   65]: batch_acc: 0.94140625
[25/05/22 22:57:34] [eval_visz.py:   49]: batch_counter=15
[25/05/22 22:57:41] [optim.py:   72]: step 226, LR: 0.000052
[25/05/22 22:57:52] [optim.py:   72]: step 227, LR: 0.000051
[25/05/22 22:58:03] [optim.py:   72]: step 228, LR: 0.000051
[25/05/22 22:58:06] [eval_visz.py:   65]: batch_acc: 0.947265625
[25/05/22 22:58:06] [eval_visz.py:   49]: batch_counter=16
[25/05/22 22:58:13] [optim.py:   72]: step 229, LR: 0.000050
[25/05/22 22:58:24] [optim.py:   72]: step 230, LR: 0.000050
[25/05/22 22:58:35] [optim.py:   72]: step 231, LR: 0.000049
[25/05/22 22:58:38] [eval_visz.py:   65]: batch_acc: 0.927734375
[25/05/22 22:58:38] [eval_visz.py:   49]: batch_counter=17
[25/05/22 22:58:45] [optim.py:   72]: step 232, LR: 0.000049
[25/05/22 22:58:56] [optim.py:   72]: step 233, LR: 0.000048
[25/05/22 22:59:07] [optim.py:   72]: step 234, LR: 0.000048
[25/05/22 22:59:10] [eval_visz.py:   65]: batch_acc: 0.92578125
[25/05/22 22:59:10] [eval_visz.py:   49]: batch_counter=18
[25/05/22 22:59:18] [optim.py:   72]: step 235, LR: 0.000047
[25/05/22 22:59:29] [optim.py:   72]: step 236, LR: 0.000047
[25/05/22 22:59:39] [optim.py:   72]: step 237, LR: 0.000046
[25/05/22 22:59:42] [eval_visz.py:   65]: batch_acc: 0.935546875
[25/05/22 22:59:42] [eval_visz.py:   49]: batch_counter=19
[25/05/22 22:59:46] [optim.py:   72]: step 238, LR: 0.000046
[25/05/22 22:59:54] [optim.py:   72]: step 239, LR: 0.000045
[25/05/22 23:00:01] [optim.py:   72]: step 240, LR: 0.000045
[25/05/22 23:00:04] [eval_visz.py:   65]: batch_acc: 0.9338235259056091
[25/05/22 23:00:04] [eval_visz.py:   49]: batch_counter=0
[25/05/22 23:00:11] [optim.py:   72]: step 241, LR: 0.000044
[25/05/22 23:00:23] [optim.py:   72]: step 242, LR: 0.000044
[25/05/22 23:00:33] [optim.py:   72]: step 243, LR: 0.000043
[25/05/22 23:00:36] [eval_visz.py:   65]: batch_acc: 0.927734375
[25/05/22 23:00:36] [eval_visz.py:   49]: batch_counter=1
[25/05/22 23:00:44] [optim.py:   72]: step 244, LR: 0.000043
[25/05/22 23:00:55] [optim.py:   72]: step 245, LR: 0.000043
[25/05/22 23:01:05] [optim.py:   72]: step 246, LR: 0.000042
[25/05/22 23:01:08] [eval_visz.py:   65]: batch_acc: 0.9453125
[25/05/22 23:01:08] [eval_visz.py:   49]: batch_counter=2
[25/05/22 23:01:16] [optim.py:   72]: step 247, LR: 0.000042
[25/05/22 23:01:27] [optim.py:   72]: step 248, LR: 0.000041
[25/05/22 23:01:37] [optim.py:   72]: step 249, LR: 0.000041
[25/05/22 23:01:41] [eval_visz.py:   65]: batch_acc: 0.947265625
[25/05/22 23:01:41] [eval_visz.py:   49]: batch_counter=3
[25/05/22 23:01:48] [optim.py:   72]: step 250, LR: 0.000041
[25/05/22 23:01:59] [optim.py:   72]: step 251, LR: 0.000040
